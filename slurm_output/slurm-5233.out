args: Namespace(seed=42, text_max_len=512, num_train_epochs=5, model_class='CMCModel', dataset_name='msmarco', label_num=0, composition='pooler', context_num=1, pretrained_bert_path='Luyu/co-condenser-marco-retriever', model_save_prefix='reg5-', top_layer_num=3, first_seq_max_len=256, train_candidate_num=-1, used_layers=None, one_stage=False, evaluate_epoch=1, no_aggregator=False, no_enricher=False, no_apex=False, no_train=False, do_test=False, do_real_test=False, query_block_size=200, do_val=False, use_cpu=False, in_batch=False, nvidia_number='1', restore=False, val_batch_size=2, train_batch_size=8, gradient_accumulation_steps=1, step_max_query_num=8, clean_graph=False, no_initial_test=False, only_final=False, load_model=False, load_model_path=None, save_model_dict='./model/', last_model_dict='./last_model/', load_middle=False, distill=False, teacher_path='./model/teacher', mlm=False, teacher_loss=True, alpha=0.5, local_rank=0, data_parallel=False, data_distribute=False, dataset_split_num=20, first_stage_lr=0.3)
local rank: 0
first time use this tokenizer, downloading...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ begin one stage train ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
---------------------- create model ----------------------
--------------------- model  created ---------------------
[{'params': <generator object Module.parameters at 0x7f5c644d3bc0>, 'lr': 1e-05}, {'params': <generator object Module.parameters at 0x7f5c644d3ca0>, 'lr': 1e-05}, {'params': <generator object Module.parameters at 0x7f5c644d3d80>, 'lr': 1e-05}, {'params': <generator object Module.parameters at 0x7f5c644d3e60>, 'lr': 1e-05}]
******************************
Traceback (most recent call last):
  File "/home/cme/MixEncoder/nlp_main.py", line 135, in <module>
    my_train_model.train(train_two_stage_flag=my_train_two_stage_flag,
  File "/home/cme/MixEncoder/nlp_trainer.py", line 163, in train
    train_dataset, val_datasets, test_datasets = self.__get_datasets()
                                                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/cme/MixEncoder/nlp_trainer.py", line 1820, in __get_datasets
    tokenized_query = torch.load(root_path + "dataset/msmarco_query_tokenized_dict")
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chaeyeonjin/miniconda3/lib/python3.11/site-packages/torch/serialization.py", line 771, in load
    with _open_file_like(f, 'rb') as opened_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chaeyeonjin/miniconda3/lib/python3.11/site-packages/torch/serialization.py", line 270, in _open_file_like
    return _open_file(name_or_buffer, mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chaeyeonjin/miniconda3/lib/python3.11/site-packages/torch/serialization.py", line 251, in __init__
    super(_open_file, self).__init__(open(name, mode))
                                     ^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/data/cme/fast_match/dataset/msmarco_query_tokenized_dict'
